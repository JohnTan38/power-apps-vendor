{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be5fe80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver # 1 login \n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://az3.ondemand.esker.com/ondemand/webaccess/asf/home.aspx\")\n",
    "driver.maximize_window()\n",
    "time.sleep(1)\n",
    "\n",
    "driver.find_element(By.XPATH, '//*[@id=\"ctl03_tbUser\"]').send_keys(\"john.tan@sh-cogent.com.sg\")\n",
    "driver.find_element(By.XPATH, '//*[@id=\"ctl03_tbPassword\"]').send_keys(\"Esker3838\")\n",
    "driver.find_element(By.XPATH, '//*[@id=\"ctl03_btnSubmitLogin\"]').click()\n",
    "time.sleep(5)\n",
    "\n",
    "def hover(driver, x_path):\n",
    "    elem_to_hover = driver.find_element(By.XPATH, x_path)\n",
    "    hover = ActionChains(driver).move_to_element(elem_to_hover)\n",
    "    hover.perform()\n",
    "\n",
    "time.sleep(3)\n",
    "x_path_hover = '//*[@id=\"mainMenuBar\"]/td/table/tbody/tr/td[36]/a/div' #arrow\n",
    "hover(driver, x_path_hover)\n",
    "time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443ac920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  company_code vendor_number                                 name\n",
      "0         SG80    1000148216          SH COGENT LOGISTICS PTE LTD\n",
      "1         SG77    1000338436         SPEEDYLINK LOGISTICS SDN BHD\n",
      "2         SG78    1000447786          AIW LOGISTICS (M) SDN. BHD.\n",
      "3         SG88    1000265996  AARDWOLF PESTKARE (SINGAPORE) PTE L\n",
      "4         SG80    1000447786          AIW LOGISTICS (M) SDN. BHD.\n",
      "5         SG79    1000152145                  HOPLITE ENGINEERING\n",
      "6         SG77    1000241177   KIM ENG SENG ENGINEERING & TRADING\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------------------\n",
    "# Iterate through log files and parse vendor data from 'Data:' sections\n",
    "# Handles fixed-width spacing and odd lines where vendor_number is glued to the name\n",
    "# ---------------------------\n",
    "\n",
    "dir_path = r\"C:/Users/john.tan/Documents/power_apps_esker_vendor/esker_vendor_update/Log/\"\n",
    "def parse_vendor_data_from_logs(dir_path: str = dir_path,\n",
    "                                recursive: bool = True,\n",
    "                                keep: str = 'first',\n",
    "                                pattern: str = \"log_2025.txt\",\n",
    "                                ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Walk `dir_path`, read all .txt files, extract the 'Data:' block rows with\n",
    "    columns [company_code, vendor_number, name], de-duplicate, and return a DataFrame.\n",
    "\n",
    "    - Handles fixed-width spacing and odd lines where vendor_number is glued to the name\n",
    "      (e.g., '1000265996AARDWOLF...').\n",
    "    - Ignores other sections like 'Process initialized/completed'.\n",
    "    \"\"\"\n",
    "    base = Path(dir_path)\n",
    "    rows = []\n",
    "\n",
    "    def parse_data_row(line: str):\n",
    "        s = line.rstrip(\"\\n\")\n",
    "        if not s.strip():\n",
    "            return None\n",
    "\n",
    "        # 1) Typical fixed-width logs: split on 2+ spaces\n",
    "        parts = re.split(r\"\\s{2,}\", s.strip())\n",
    "        if len(parts) >= 3:\n",
    "            company_code = parts[0].strip()\n",
    "            vendor_number = parts[1].strip()\n",
    "            name = \" \".join(parts[2:]).strip()\n",
    "\n",
    "            # If vendor_number accidentally includes the start of the name, split it\n",
    "            m2 = re.match(r\"^(\\d{5,})([A-Za-z].*)$\", vendor_number)\n",
    "            if m2:\n",
    "                vendor_number = m2.group(1)\n",
    "                name = (m2.group(2) + (\" \" + name if name else \"\")).strip()\n",
    "            return company_code, vendor_number, name\n",
    "\n",
    "        # 2) Fallback: token, digits, then glued name\n",
    "        m = re.match(r\"^\\s*(\\S+)\\s+(\\d{5,})([A-Za-z].+)$\", s)\n",
    "        if m:\n",
    "            return m.group(1), m.group(2), m.group(3).strip()\n",
    "\n",
    "        # 3) Very loose: token, token, rest (and split leading digits if present)\n",
    "        m = re.match(r\"^\\s*(\\S+)\\s+(\\S+)\\s+(.+)$\", s)\n",
    "        if m:\n",
    "            company_code, vendor_number, name = m.group(1), m.group(2), m.group(3).strip()\n",
    "            m3 = re.match(r\"^(\\d{5,})([A-Za-z].*)$\", vendor_number)\n",
    "            if m3:\n",
    "                vendor_number = m3.group(1)\n",
    "                name = (m3.group(2) + \" \" + name).strip()\n",
    "            return company_code, vendor_number, name\n",
    "\n",
    "        return None\n",
    "\n",
    "    for fp in base.rglob(\"*.txt\"):\n",
    "        try:\n",
    "            lines = fp.read_text(encoding=\"utf-8\", errors=\"ignore\").splitlines()\n",
    "        except Exception:\n",
    "            continue  # skip unreadable files\n",
    "\n",
    "        i, n = 0, len(lines)\n",
    "        while i < n:\n",
    "            if lines[i].strip().startswith(\"Data:\"):\n",
    "                # Skip to header (next non-empty line)\n",
    "                i += 1\n",
    "                while i < n and not lines[i].strip():\n",
    "                    i += 1\n",
    "                # header line present but we don't need to parse it strictly\n",
    "                i += 1\n",
    "                # Read data rows until blank/new section\n",
    "                while i < n:\n",
    "                    cur = lines[i]\n",
    "                    cur_stripped = cur.strip()\n",
    "                    if (not cur_stripped) or cur_stripped.startswith((\"Process completed\", \"Process initialized\", \"Updated\", \"Data:\")):\n",
    "                        break\n",
    "                    # Skip accidental header repeats\n",
    "                    if {\"company_code\", \"vendor_number\", \"name\"}.issubset(set(re.split(r\"\\s+\", cur_stripped))):\n",
    "                        i += 1\n",
    "                        continue\n",
    "                    parsed = parse_data_row(cur)\n",
    "                    if parsed:\n",
    "                        rows.append(parsed)\n",
    "                    i += 1\n",
    "            else:\n",
    "                i += 1\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=[\"company_code\", \"vendor_number\", \"name\"]) if rows else pd.DataFrame(columns=[\"company_code\", \"vendor_number\", \"name\"])\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].astype(str).str.strip()\n",
    "    \n",
    "\n",
    "    #write to csv for checking and persistent storage\n",
    "    with open(dir_path + 'parsed_vendor_data.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "        df.drop_duplicates().reset_index(drop=True)\n",
    "        df.to_csv(f, index=False)\n",
    "    return df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "df_vendor_updated = parse_vendor_data_from_logs()\n",
    "print(df_vendor_updated)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
